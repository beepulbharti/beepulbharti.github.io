<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Beepul Bharti</title> <meta name="author" content="Beepul Bharti"/> <meta name="description" content=""/> <meta name="keywords" content="phd, student, machine learning, fairness, interpretability"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <script src="https://kit.fontawesome.com/dc8028114a.js" crossorigin="anonymous"></script> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://beepulbharti.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-G79V0DM9ZM"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-G79V0DM9ZM");</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="https://github.com/beepulbharti" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fa-brands fa-github"></i></a> <a href="https://scholar.google.com/citations?user=_aKpVoEAAAAJ&amp;hl=en" title="Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar-square"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/assets/pdf/cv.pdf" target="_blank">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Beepul Bharti </h1> <p class="desc">PhD Student @ JHU</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/prof_pic.jpg" width="auto" height="auto" alt="prof_pic.jpg"> </picture> </figure> <div class="address"> </div> </div> <div class="clearfix"> <p>Hi everyone, my name is Beepul Bharti! I am a PhD student in the <a href="https://www.bme.jhu.edu/academics/graduate/phd-program/" target="_blank" rel="noopener noreferrer">Biomedical Engineering Department</a> at <a href="https://www.jhu.edu" target="_blank" rel="noopener noreferrer">Johns Hopkins University</a>, where I am very fortunate to be advised by <a href="https://sites.google.com/view/jsulam" target="_blank" rel="noopener noreferrer">Dr. Jeremias Sulam</a> and be affiliated with the JHU Mathematical Institute of Data Science <a href="https://www.minds.jhu.edu" target="_blank" rel="noopener noreferrer">(MINDS)</a> . My PhD research focuses on the statistical understanding of machine learning (ML), the interpretability and fairness of ML algorithms, and how to responsibly utilize/deploy these algorithms in high-stakes decision areas such as governance and healthcare.</p> <p>Prior to my PhD, I completed my BS in Biomedical Engineering, BA in Mathematics, and minor in Chemistry from <a href="https://duke.edu" target="_blank" rel="noopener noreferrer">Duke University</a>.</p> <p>In my spare time, I enjoy running, playing soccer, watching basketball, and spending time with family and friends.</p> </div> <div class="news"> <h2>news</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Mar, 2025</th> <td> Our paper “<a href="https://openreview.net/pdf?id=H43BmpeJII" target="_blank" rel="noopener noreferrer">Sufficient and Necessary Explanations (and What Lies in Between)</a>” has been accepted to the Conference on Parsimony and Learning (CPAL) 2025. </td> </tr> <tr> <th scope="row">Aug, 2024</th> <td> I spent the Summer of 2024 interning at <a href="https://www.gene.com" target="_blank" rel="noopener noreferrer">Genentech</a> as a ML/AI Intern working with the Deep Learning Theory and Algorithms team within the Biology Research/AI Development department. Thank you Genentech and specifically Alex Tseng for hosting me! </td> </tr> <tr> <th scope="row">Dec, 2023</th> <td> Our paper “<a href="https://openreview.net/forum?id=WFtTpQ47A7&amp;referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DTMLR%2FAuthors%23your-submissions)" target="_blank" rel="noopener noreferrer">SHAP-XRT: The Shapley Value Meets Conditional Independence Testing</a>” has been accepted to Transactions on Machine Learning Research! </td> </tr> <tr> <th scope="row">Sep, 2023</th> <td> Our paper “<a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/752820c79b4ebb72809014bdfdedd603-Abstract-Conference.html" target="_blank" rel="noopener noreferrer">Estimating and Controlling for Equalized Odds via Sensitive Attribute Predictors</a>” has been accepted to NeurIPS 2023! </td> </tr> <tr> <th scope="row">Sep, 2023</th> <td> I had a great time attending the <a href="https://www.slmath.org/workshops/1051" target="_blank" rel="noopener noreferrer">SLMath Introductory Workshop: Algorithms, Fairness,and Equity</a>! Thank you to <a href="https://www.slmath.org" target="_blank" rel="noopener noreferrer">SLMath</a> for hosting us and to all the speakers for their great talks! </td> </tr> <tr> <th scope="row">Jan, 2022</th> <td> Awarded the 2022 Spring &amp; Summer Data Science Fellowship by (<a href="https://www.minds.jhu.edu" target="_blank" rel="noopener noreferrer">MINDS</a>) </td> </tr> </table> </div> </div> <div class="publications"> <h2>preprints</h2> <ol class="bibliography"></ol> </div> <div class="publications"> <h2>publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <div class="published-date">March. 12, 2025</div> <abbr class="badge">CPAL</abbr> </div> <div id="bharti2025sufficient" class="col-sm-9"> <div class="title"><a href="https://openreview.net/forum?id=H43BmpeJII" target="_blank" rel="noopener noreferrer">Sufficient and Necessary Explanations (and What Lies in Between)</a></div> <div class="author"> <em>Bharti, B.</em>, Yi, P., and <a href="https://sites.google.com/view/jsulam" target="_blank" rel="noopener noreferrer">Sulam, J.</a> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button" style="margin-left:0">Abstract</a> </div> <div class="abstract hidden"> <p>As complex machine learning models continue to be used in high-stakes decision settings, understanding their predictions is crucial. Post-hoc explanation methods aim to identify which features of an input x are important to a model’s prediction f(x). However, explanations often vary between methods and lack clarity, limiting the information we can draw from them. To address this, we formalize two precise concepts—sufficiency and necessity—to quantify how features contribute to a model’s prediction. We demonstrate that, although intuitive and simple, these two types of explanations may fail to fully reveal which features a model deems important. To overcome this, we propose and study a unified notion of importance that spans the entire sufficiency-necessity axis. Our unified notion, we show, has strong ties to notions of importance based on conditional independence and Shapley values. Lastly, through various experiments, we quantify the sufficiency and necessity of popular post-hoc explanation methods. Furthermore, we show that generating explanations along the sufficiency-necessity axis can uncover important features that may otherwise be missed, providing new insights into feature importance.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <div class="published-date">Dec. 13, 2023</div> <abbr class="badge">NeurIPS</abbr> </div> <div id="bharti2023estimating" class="col-sm-9"> <div class="title"><a href="https://nips.cc/virtual/2023/poster/70984" target="_blank" rel="noopener noreferrer">Estimating and Controlling for Equalized Odds via Sensitive Attribute Predictors</a></div> <div class="author"> <em>Bharti, B.</em>, Yi, P., and <a href="https://sites.google.com/view/jsulam" target="_blank" rel="noopener noreferrer">Sulam, J.</a> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button" style="margin-left:0">Abstract</a> </div> <div class="abstract hidden"> <p>As the use of machine learning models in real world high-stakes decision settings continues to grow, it is highly important that we are able to audit and control for any potential fairness violations these models may exhibit towards certain groups. To do so, one naturally requires access to sensitive attributes, such as demographics, biological sex, or other potentially sensitive features that determine group membership. Unfortunately, in many settings, this information is often unavailable. In this work we study the well known equalized odds (EOD) definition of fairness. In a setting without sensitive attributes, we first provide tight and computable upper bounds for the EOD violation of a predictor. These bounds precisely reflect the worst possible EOD violation. Second, we demonstrate how one can provably control the worst-case EOD by a new post-processing correction method. Our results characterize when directly controlling for EOD with respect to the predicted sensitive attributes is – and when is not – optimal when it comes to controlling worst-case EOD. Our results hold under assumptions that are milder than previous works, and we illustrate these results with experiments on synthetic and real datasets.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <div class="published-date">Dec. 12, 2023</div> <abbr class="badge">TMLR</abbr> </div> <div id="bharti2023shapley" class="col-sm-9"> <div class="title"><a href="https://openreview.net/forum?id=WFtTpQ47A7" target="_blank" rel="noopener noreferrer">SHAP-XRT: The Shapley Value Meets Conditional Independence Testing</a></div> <div class="author">Teneggi, J.*,  <em>Bharti, B.*</em>, <a href="https://sites.google.com/view/yaniv-romano/" target="_blank" rel="noopener noreferrer">Romano, Y.</a>, and <a href="https://sites.google.com/view/jsulam" target="_blank" rel="noopener noreferrer">Sulam, J.</a> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button" style="margin-left:0">Abstract</a> </div> <div class="abstract hidden"> <p>The complex nature of artificial neural networks raises concerns on their reliability, trustworthiness, and fairness in real-world scenarios. The Shapley value—a solution concept from game theory—is one of the most popular explanation methods for machine learning models. More traditionally, from a statistical perspective, feature importance is defined in terms of conditional independence. So far, these two approaches to interpretability and feature importance have been considered separate and distinct. In this work, we show that Shapley-based explanation methods and conditional independence testing are closely related. We introduce the SHAPley-EXplanation Randomization Test (SHAP-XRT), a testing procedure inspired by the Conditional Randomization Test (CRT) for a specific notion of local (i.e., on a sample) conditional independence. With it, we prove that for binary classification problems, the marginal contributions in the Shapley value provide lower and upper bounds to the p-values of their respective tests. Furthermore, we show that the Shapley value itself provides an upper bound to the p-value of a global (i.e., overall) null hypothesis. As a result, we further our understanding of Shapley-based explanation methods from a novel perspective and characterize under which conditions one can make statistically valid claims about feature importance via the Shapley value.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <div class="published-date">Aug. 30, 2022</div> <abbr class="badge">CAR</abbr> </div> <div id="li2023sex" class="col-sm-9"> <div class="title"><a href="https://journals.sagepub.com/doi/full/10.1177/08465371221120539?casa_token=ZJFwAIVn9sYAAAAA:RBdW9octj6zH0CLSmGytB0d00v_Kzp7Qyr091zN-u88DDAu80gSKuP2pQJ8EE_fBUjMXCYz9WB6v2Q" target="_blank" rel="noopener noreferrer">Sex imbalance produces biased deep learning models for knee osteoarthritis detection</a></div> <div class="author">Li, D.,  <em>Bharti, B.</em>, Wei, J., <a href="https://sites.google.com/view/jsulam" target="_blank" rel="noopener noreferrer">Sulam, J.</a>, and Yi, P. </div> <div class="links"> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Beepul Bharti. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Last updated: March 13, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>