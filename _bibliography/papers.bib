---
---
@article{bharti2023estimating,
  title        = {Estimating and Controlling for Equalized Odds via Sensitive Attribute Predictors},
  author       = {Bharti, Beepul and Yi, Paul and Sulam, Jeremias},
  booktitle    = {Thirty-seventh Conference on Neural Information Processing Systems},
  year         = {2023},
  selected     = {true},
  abbr         = {NeurIPS},
  date         = {Dec. 13, 2023},
  url          = {https://nips.cc/virtual/2023/poster/70984},
  abstract     = {As the use of machine learning models in real world high-stakes decision settings continues to grow, it is highly important that we are able to audit and control for any potential fairness violations these models may exhibit towards certain groups. To do so, one naturally requires access to sensitive attributes, such as demographics, biological sex, or other potentially sensitive features that determine group membership. Unfortunately, in many settings, this information is often unavailable. In this work we study the well known equalized odds (EOD) definition of fairness. In a setting without sensitive attributes, we first provide tight and computable upper bounds for the EOD violation of a predictor. These bounds precisely reflect the worst possible EOD violation. Second, we demonstrate how one can provably control the worst-case EOD by a new post-processing correction method. Our results characterize when directly controlling for EOD with respect to the predicted sensitive attributes is -- and when is not -- optimal when it comes to controlling worst-case EOD. Our results hold under assumptions that are milder than previous works, and we illustrate these results with experiments on synthetic and real datasets.}
}

@article{bharti2023shapley,
  title        = {SHAP-XRT: The Shapley Value Meets Conditional Independence Testing},
  author       = {Teneggi, Jacopo* and Bharti, Beepul* and Romano, Yaniv and Sulam, Jeremias},
  booktitle    = {Transactions of Machine Learning Research},
  year         = {2023},
  selected     = {true},
  abbr         = {TMLR},
  date         = {Dec. 12, 2023},
  url          = {https://openreview.net/forum?id=WFtTpQ47A7},
  abstract     = {The complex nature of artificial neural networks raises concerns on their reliability, trustworthiness, and fairness in real-world scenarios. The Shapley value---a solution concept from game theory---is one of the most popular explanation methods for machine learning models. More traditionally, from a statistical perspective, feature importance is defined in terms of conditional independence. So far, these two approaches to interpretability and feature importance have been considered separate and distinct. In this work, we show that Shapley-based explanation methods and conditional independence testing are closely related. We introduce the SHAPley-EXplanation Randomization Test (SHAP-XRT), a testing procedure inspired by the Conditional Randomization Test (CRT) for a specific notion of local (i.e., on a sample) conditional independence. With it, we prove that for binary classification problems, the marginal contributions in the Shapley value provide lower and upper bounds to the p-values of their respective tests. Furthermore, we show that the Shapley value itself provides an upper bound to the p-value of a global (i.e., overall) null hypothesis. As a result, we further our understanding of Shapley-based explanation methods from a novel perspective and characterize under which conditions one can make statistically valid claims about feature importance via the Shapley value.}
}

@article{li2023sex,
  title={Sex imbalance produces biased deep learning models for knee osteoarthritis detection},
  author={Li, David and Bharti, Beepul and Wei, Jinchi and Sulam, Jeremias and Yi, Paul H},
  journal={Canadian Association of Radiologists Journal},
  pages={219--221},
  year={2023},
  selected={true},
  abbr={CAR},
  date={Aug. 30, 2022},
  url={https://journals.sagepub.com/doi/full/10.1177/08465371221120539?casa_token=ZJFwAIVn9sYAAAAA:RBdW9octj6zH0CLSmGytB0d00v_Kzp7Qyr091zN-u88DDAu80gSKuP2pQJ8EE_fBUjMXCYz9WB6v2Q},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

